{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tanh in module torch.nn.functional:\n",
      "\n",
      "tanh(input)\n",
      "    tanh(input) -> Tensor\n",
      "    \n",
      "    Applies element-wise,\n",
      "    :math:`\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}`\n",
      "    \n",
      "    See :class:`~torch.nn.Tanh` for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(F.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root = 'data', train = True,\n",
    "                                   download = True, transform = transform)\n",
    "test_data = datasets.MNIST(root = 'data', train = False,\n",
    "                                  download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923, 10)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.eye(10)[train_data.targets.numpy()][train_data.targets.numpy() == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_data.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.data.view(60000, -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.data.view(10000, -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18065,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[train_label > 6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [train_data[train_label == i] for i in [7, 8, 9]]\n",
    "test_sets = [test_data[test_label ==i] for i in [7, 8, 9]]\n",
    "train_labels = [train_label[train_label == i] for i in [7, 8, 9]]\n",
    "test_labels = [test_label[test_label == i] for i in [7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = min(map(len, train_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = min(map(len, test_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array([[train_sets[j][i] for j in range(3)] for i in range(train_size)])\n",
    "train_label = np.array([[train_labels[j][i] for j in range(3)] for i in range(train_size)])\n",
    "\n",
    "test_data = np.array([[test_sets[j][i] for j in range(3)] for i in range(test_size)])\n",
    "test_label = np.array([[test_labels[j][i] for j in range(3)] for i in range(test_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(974, 3, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label * 0.75 - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label * 0.75 - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label + 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label + 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-76d1540cbc5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "for _, (x, y) in enumerate(loader):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch.utils.data in torch.utils:\n",
      "\n",
      "NAME\n",
      "    torch.utils.data\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _utils (package)\n",
      "    dataloader\n",
      "    dataset\n",
      "    distributed\n",
      "    sampler\n",
      "\n",
      "FILE\n",
      "    /Users/zhipeng/Library/Python/3.7/lib/python/site-packages/torch/utils/data/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Data.DataLoader(Data.TensorDataset(torch.FloatTensor(train_data), torch.FloatTensor(train_label)), \n",
    "                        batch_size = 5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionL2RNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionL2RNet, self).__init__()\n",
    "        \n",
    "        self.q_h1 = nn.Linear(784, 256)\n",
    "        #self.q_h2 = nn.Linear(256, 784)\n",
    "        self.q_b = nn.LayerNorm(256)\n",
    "        self.q_h3 = nn.Linear(256, 32)\n",
    "        \n",
    "        self.v_h1 = nn.Linear(784, 256)\n",
    "        #self.v_h2 = nn.Linear(256, 784)\n",
    "        self.v_b = nn.LayerNorm(256)\n",
    "        self.v_h3 = nn.Linear(256, 32)\n",
    "        \n",
    "        self.k_h1 = nn.Linear(784, 256)\n",
    "        #self.k_h2 = nn.Linear(256, 784)\n",
    "        self.k_b = nn.LayerNorm(256)\n",
    "        self.k_h3 = nn.Linear(256, 32)\n",
    "        \n",
    "        self.h1 = nn.Linear(32, 64)\n",
    "        self.h2 = nn.Linear(64, 32)\n",
    "        self.h3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def b_forward(self, x):\n",
    "        x = F.relu(self.s_1(x)) + x\n",
    "        x = self.d_1(x)\n",
    "        x = F.relu(self.s_2(x))\n",
    "        x = self.d_2(x)\n",
    "        x = self.s_3(x)\n",
    "        return F.softmax(x.view(x.size(0), x.size(1)), dim = 1)\n",
    "    \n",
    "        \n",
    "    def _get_kqv(self, inp, h1, b, h3):\n",
    "        x = F.relu(h1(inp))\n",
    "        x = b(x)\n",
    "        return h3(x)\n",
    "    \n",
    "    def _attn_code(self, x):\n",
    "        query = self._get_kqv(x, self.q_h1, self.q_b, self.q_h3)\n",
    "        value = self._get_kqv(x, self.v_h1, self.v_b, self.v_h3)\n",
    "        key = self._get_kqv(x, self.k_h1, self.k_b, self.k_h3)\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(d_k)\n",
    "        attn = F.softmax(scores, dim = -1)\n",
    "        return torch.matmul(attn, value)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        inp = self._attn_code(inp)\n",
    "        #print(inp)\n",
    "        x = F.relu(self.h1(inp))\n",
    "        x = F.relu(self.h2(x)) + inp\n",
    "        x = self.h3(x)\n",
    "        #return x.view(x.shape[0], x.shape[1])\n",
    "        #return F.tanh(x.view(x.size(0), x.size(1))) / 3.0\n",
    "        return F.softmax(x.view(x.size(0), x.size(1)), dim = 1) + F.tanh(x.view(x.size(0), x.size(1))) / 3.0\n",
    "        #return F.softmax(x.view(x.size(0), x.size(1)), dim = 1) - 0.33\n",
    "        #tmp = F.tanh(x.view(x.size(0), x.size(1)))\n",
    "        #return tmp / torch.abs(tmp).sum(dim = 1).unsqueeze(1)\n",
    "        #tmp = F.softmax(x.view(x.size(0), x.size(1)), dim = 1)\n",
    "        #return tmp - tmp.mean(dim = 1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[:, 0] = -0.01\n",
    "train_label[:, 1] = 0.02\n",
    "train_label[:, 2] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = AttentionL2RNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5348, 0.5419, 0.5453]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(torch.FloatTensor(train_data[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(m.parameters(), lr = 1e-5)\n",
    "loader = Data.DataLoader(Data.TensorDataset(torch.FloatTensor(train_data), torch.FloatTensor(train_label)), \n",
    "                        batch_size = 250, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0227, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0229, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0224, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0226, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0229, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0226, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0229, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0229, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0229, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0229, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0231, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0232, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0233, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0237, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0240, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0239, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0247, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0247, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0244, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0247, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    for _, (x, y) in enumerate(loader):\n",
    "        \n",
    "        x, y = Variable(x), Variable(y)\n",
    "        oup = m(x)\n",
    "        loss = torch.mean(-y * oup)\n",
    "        #loss = torch.mean((y - oup) ** 2)\n",
    "        print(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = m(Variable(torch.FloatTensor(test_data))).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x140a0c050>"
      ]
     },
     "execution_count": 1302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(result[:, 0])\n",
    "sns.distplot(result[:, 1])\n",
    "sns.distplot(result[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916"
      ]
     },
     "execution_count": 1303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero((result[:, 1] > result[:, 0]) & (result[:, 2] > result[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(974, 3)"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_l.data_reader_writer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'id': 'a', 'product': 'b', 'the_date': 'c',\n",
    "                   'side': 'b', 'data_type': 'd', 'data_content': 'e'\n",
    "                   }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product</th>\n",
       "      <th>the_date</th>\n",
       "      <th>side</th>\n",
       "      <th>data_type</th>\n",
       "      <th>data_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id product the_date side data_type data_content\n",
       "0  a       b        c    b         d            e"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('FACTOR_SIGNAL', create_connection(ML_DB_PATH), if_exists = 'replace', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product</th>\n",
       "      <th>the_date</th>\n",
       "      <th>side</th>\n",
       "      <th>data_type</th>\n",
       "      <th>data_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id product the_date side data_type data_content\n",
       "0  a       b        c    b         d            e"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df_from_sql('select * from FACTOR_SIGNAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(create_connection(ML_DB_PATH), 'delete from FACTOR_SIGNAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0   0   1\n",
       "1   2   3\n",
       "2   4   5\n",
       "3   6   7\n",
       "4   8   9\n",
       "5  10  11\n",
       "6  12  13\n",
       "7  14  15\n",
       "8  16  17\n",
       "9  18  19"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].apply(lambda x: pd.Series([2 * x, 2 * x  + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1])"
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_t = (train_label % 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_t = (test_label % 2) *  2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 28 ** 2\n",
    "HIDDEN_DIM = INPUT_DIM // 2\n",
    "class FNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNet, self).__init__()\n",
    "        self.h1 = nn.Linear(INPUT_DIM, 2 * INPUT_DIM)\n",
    "        self.h5 = nn.Linear(2 * INPUT_DIM, 1)\n",
    "\n",
    "    def predict(self, inp):\n",
    "        x = F.tanh(self.h1(inp))\n",
    "        x = self.h5(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.predict(inp)\n",
    "        return F.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = FNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(p.parameters(), lr = 1)\n",
    "loader = Data.DataLoader(Data.TensorDataset(torch.FloatTensor(train_data), torch.FloatTensor(train_label_t)), \n",
    "                        batch_size = 250, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhipeng/Library/Python/3.7/lib/python/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):    \n",
    "    for _, (x, y) in enumerate(loader):\n",
    "        \n",
    "        x, y = Variable(x), Variable(y)\n",
    "        oup = p(x)\n",
    "        #loss = torch.sum(-y * oup)\n",
    "        loss = torch.mean((y - oup) ** 2)\n",
    "        #print(loss)\n",
    "        #loss = torch.mean(-y * torch.log(oup))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = p(Variable(torch.FloatTensor(train_data))).view(60000).detach().numpy()\n",
    "test_result = p(Variable(torch.FloatTensor(test_data))).view(10000).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loss = np.mean((train_result - train_label_t) ** 2)\n",
    "#test_loss = np.mean((test_result - test_label_t) ** 2)\n",
    "train_loss = np.mean(-train_label_t * train_result)\n",
    "test_loss = np.mean(-test_label_t * test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546929267766345 0.5409217777084917\n",
      "0.5424550232681657 0.5359495343860119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.016932764634490012, 0.014799465847015381)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(train_result, train_label_t)\n",
    "eval(test_result, test_label_t)\n",
    "train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(pred, signal):\n",
    "    aupr = average_precision_score(signal > 0, pred)\n",
    "    auroc = roc_auc_score(signal > 0, pred)\n",
    "    print(aupr, auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6675161150492755 0.6928053173460174\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ..., -1,  1, -1])"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12b3a5910>"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.distplot(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
